{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import librosa\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting sampling rate default = 22050\n",
    "sr = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'recordedAudio.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recordedAudio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(\u001b[43mrecordedAudio\u001b[49m\u001b[38;5;241m.\u001b[39mwav)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'recordedAudio' is not defined"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.8053570e-09, -8.0805487e-09,  1.9261781e-09, ...,\n",
       "        8.9211106e-02, -1.8516523e-01, -4.8153207e-02], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m vosk_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvosk-model-small-en-us-0.15\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(vosk_model_path)\n\u001b[1;32m----> 4\u001b[0m recognizer \u001b[38;5;241m=\u001b[39m KaldiRecognizer(model, \u001b[43msr\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sr' is not defined"
     ]
    }
   ],
   "source": [
    "# Setting Model Vosk\n",
    "vosk_model_path = \"vosk-model-small-en-us-0.15\" \n",
    "model = Model(vosk_model_path)\n",
    "recognizer = KaldiRecognizer(model, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Recognizer\n",
    "def recognizer_audio(pcm_data):\n",
    "    recognizer.AcceptWaveform(pcm_data)\n",
    "    result = recognizer.FinalResult()\n",
    "    result_dict = json.loads(result)\n",
    "    print(result_dict['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Detecting Unvoice Frame by Librosa\n",
    "custom_ref = 0.2\n",
    "top_db = 20\n",
    "def split_on_silence(y, sr):\n",
    "    intervals = librosa.effects.split(y, top_db=top_db, ref=custom_ref)\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Path_Folder\n",
    "folder_path = 'audio_files'\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('([0-9]+)', s)]\n",
    "\n",
    "files.sort(key=natural_sort_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the birds canoes lid on the smooth plane\n",
      "glue the see to the doctor background\n",
      "it was easy to tell the death of a well\n",
      "\n",
      "the sega mega they were dish\n",
      "right and often served and round bowls\n",
      "good use of lemons makes find punch\n",
      "the boxes on the side the punch up\n",
      "the hunter said shop coin and garbage\n",
      "\n",
      "for our the steady work sisters\n",
      "a large times\n",
      "even hard to sell\n"
     ]
    }
   ],
   "source": [
    "array_temps = []\n",
    "\n",
    "for i, filename in enumerate(files):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    y, sr = librosa.load(file_path) \n",
    "    intervals_array = split_on_silence(y, sr)\n",
    "\n",
    "    # Case 1: Audio has all unvoice frame\n",
    "    if intervals_array.size == 0: \n",
    "        pcm_data = b''.join([(temp * 32767).astype(np.int16).tobytes() for temp in array_temps])\n",
    "        recognizer_audio(pcm_data)\n",
    "        array_temps = []\n",
    "    else:\n",
    "        # Case 2: Audio has the unvoice at the first, has the voice at the end\n",
    "        if (np.subtract(intervals_array[0][0], 0) < 500) and (np.subtract(sr, intervals_array[-1][1]) < 2000):\n",
    "            pcm_data = b''.join([(temp * 32767).astype(np.int16).tobytes() for temp in array_temps])\n",
    "            recognizer_audio(pcm_data)\n",
    "            array_temps = []\n",
    "            array_temps.append(y)\n",
    "        # Case 3: Audio has the unvoice at the end, has the voice at the first\n",
    "        elif (np.subtract(intervals_array[0][0], 0) > 500) and (np.subtract(sr, intervals_array[-1][1]) > 2000):\n",
    "            array_temps.append(y)\n",
    "            pcm_data = b''.join([(temp * 32767).astype(np.int16).tobytes() for temp in array_temps])\n",
    "            recognizer_audio(pcm_data)\n",
    "            array_temps = []\n",
    "        # Case 4: Audio has all voice frame    \n",
    "        else:\n",
    "            array_temps.append(y)\n",
    "\n",
    "# Case 5: Last Audio\n",
    "if array_temps:\n",
    "    pcm_data = b''.join([(temp * 32767).astype(np.int16).tobytes() for temp in array_temps])\n",
    "    recognizer_audio(pcm_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
